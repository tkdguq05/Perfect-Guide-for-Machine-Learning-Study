# 파이썬 머신러닝 완벽가이드 스터디 4회
20.04.06 스터디 4회   
치킨과 피자를 먹음, 기획팀 재홍 주임님 참여 
19시 30분 부터 시작. 2시간 정도 한 것 같다.


## 스터디 중 나온 질문 답변
1. 질문 : 왜 가파르게 확 올라가는 AUC가 좋은 모델인가?
   답변 : 구주임님 블로그 참고, ROC 커브를 그리는 이유, 적절한 Threshold를 찾기 위함, Threshold에 따라 맞춘 positive의 값이 올라가게 되는데, 이게 잘되면 가파르게 확 올라가는 모양이 될 것. 이렇게 가파르게 올라가는 ROC커브는 모델이 잘 만들어 졌다는 것을 의미
  
	

	


## 책을 보면서 인상적인 부분
**인상적인 부분** 
- 정밀도를 더 봐야할지, 재현율을 더 봐야할지 고민해 봐야함, 추천의 경우라면?, 추천을 받았는데 선호하는 아이템이 아닌 경우가 별로 일 것 같다. 추천 관심도 없었는데 괜찮아서 구매할 수도 있음. 
	- 추천은 정밀도 밖에 측정되지 않음. 추천에서는 coverage를 사용하기도 함. 
	- 추천의 결과로 재현율을 알 수 없음. 추천받은 사람의 반응은 구할 수 있으나, 추천 안받은 사람의 반응은 구할 수 없다. 
		- coverage : 실제 구매한 30개, 예측한 30개를 겹쳐봐서 교집합을 구함
- 우리가 하는 eager learning은 imbalance data에 대응하기 위한 것임
- AUC를 높게 만드는 방법, AUC의 해석에 대하여
	- 임계점으로 Positive, Negative를 제대로 나눌 수 없으면 AUC는 낮다. 임계점으로 Pos, Neg를 잘 나눌 수 있으면 AUC값은 높게 나온다. [구국원님 블로그](https://kgwon.github.io/ml/2020-01-02-roc-and-auc)
- F1 score는 사실 가중치에 대한 것이다
	- recall을 중요하게? precision을 중요하게? 여기에 따라서 F에 붙은 숫자가 달라진다.
	- 조화평균을 사용하는 이유, TP와 TN는 고정된 값이고, 나머지 값은 기준에 따라 변화하는 값이니까, 비율을 맞춰주기 위해서 조화평균을 사용함. F1 score는 둘을 동등하게 보려는 것